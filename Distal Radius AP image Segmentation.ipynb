{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import *\n",
    "from keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D, concatenate, Activation,Conv2DTranspose\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, History, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import backend as keras\n",
    "from keras.utils.multi_gpu_utils import multi_gpu_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import cv2\n",
    "from segmentation_GP import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkfolder(folder):\n",
    "\n",
    "    for j in range(len(folder)):\n",
    "        if not os.path.lexists(folder[j]):\n",
    "            os.makedirs(folder[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data ##\n",
    "data_path = './3_deepdata/1_exp1/train/AP_aug_img/'\n",
    "label_path = './3_deepdata/1_exp1/train/AP_aug_label/'\n",
    "\n",
    "## test data ##\n",
    "test_path = './3_deepdata/1_exp1/test/AP_pre_img/'\n",
    "test_label_path = './3_deepdata/1_exp1/test/AP_pre_label/'\n",
    "\n",
    "## npy file ##\n",
    "npy_path = './3_deepdata/1_exp1/npy/AP/'\n",
    "check_model_path = './4_result/exp1/snapshot/AP/'\n",
    "predict_path = './4_result/exp1/result/AP/'\n",
    "\n",
    "## img ##\n",
    "img_rows, img_cols = 512, 512\n",
    "img_type = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = [npy_path, check_model_path, predict_path]\n",
    "mkfolder(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating test images...\n",
      "------------------------------\n",
      "0/254\n",
      "100/254\n",
      "200/254\n",
      "loading done\n",
      "Saving to imgs_test.npy files done.\n"
     ]
    }
   ],
   "source": [
    "# create_train_data(data_path, label_path, npy_path, img_rows, img_cols, 'train', img_type)\n",
    "create_test_data(test_path, test_label_path, npy_path, img_rows, img_cols, 'test', img_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "load train images...\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "------------------------------\n",
      "load test images...\n",
      "------------------------------\n",
      "(10140, 512, 512, 1)\n",
      "(10140, 512, 512, 1)\n",
      "(254, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "imgs_train, imgs_mask_train, imgs_test = load_data(npy_path+'train.npy', \n",
    "                                                   npy_path+'train_label.npy', \n",
    "                                                   npy_path+'test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(img_rows, img_cols):\n",
    "    inputs = Input((img_rows, img_cols,1))\n",
    "    conv1 = Conv2D(32, (3, 3), activation=None, padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation=None, padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation=None, padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation=None, padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation=None, padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation=None, padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation=None, padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation=None, padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation=None, padding='same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "    conv5 = Conv2D(512, (3, 3), activation=None, padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation=None, padding='same')(up6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Activation('relu')(conv6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation=None, padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Activation('relu')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation=None, padding='same')(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Activation('relu')(conv7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation=None, padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Activation('relu')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation=None, padding='same')(up8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Activation('relu')(conv8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation=None, padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Activation('relu')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation=None, padding='same')(up9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Activation('relu')(conv9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation=None, padding='same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Activation('relu')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "def sens(y_target, y_pred): # sensitivity, recall\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sch(epoch):\n",
    "    if epoch>100 and epoch<=250:\n",
    "        return 0.0001\n",
    "    elif epoch>250:\n",
    "        return 0.00001\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "load unet model\n",
      "------------------------------\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.5/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "print('-'*30)\n",
    "print(\"load unet model\")\n",
    "print('-'*30)\n",
    "\n",
    "model = get_unet(img_rows, img_cols)\n",
    "model = multi_gpu_model(model,gpus=2)\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss=dice_coef_loss, metrics=['accuracy', sens, dice_coef_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(check_model_path+'ap_aug_exp1_{epoch:d}_{loss:f}.hdf5', monitor='val_dice_coef_loss',verbose=1, save_best_only=True)\n",
    "# sc = LearningRateScheduler(sch)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_dice_coef_loss', factor=0.8, min_delta = 0.01, patience=5, min_lr=1e-6, verbose=1)\n",
    "earlystopping = EarlyStopping(monitor='val_dice_coef_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "Train on 8112 samples, validate on 2028 samples\n",
      "Epoch 1/200\n",
      "8112/8112 [==============================] - 276s 34ms/step - loss: 0.4522 - accuracy: 0.9547 - sens: 0.9295 - dice_coef_loss: 0.4522 - val_loss: 0.3478 - val_accuracy: 0.9824 - val_sens: 0.9079 - val_dice_coef_loss: 0.3478\n",
      "\n",
      "Epoch 00001: val_dice_coef_loss improved from inf to 0.34784, saving model to ./4_result/exp1/snapshot/AP/ap_aug_exp1_1_0.452165.hdf5\n",
      "Epoch 2/200\n",
      "8112/8112 [==============================] - 272s 34ms/step - loss: 0.2286 - accuracy: 0.9924 - sens: 0.9616 - dice_coef_loss: 0.2286 - val_loss: 0.2099 - val_accuracy: 0.9863 - val_sens: 0.9461 - val_dice_coef_loss: 0.2101\n",
      "\n",
      "Epoch 00002: val_dice_coef_loss improved from 0.34784 to 0.21007, saving model to ./4_result/exp1/snapshot/AP/ap_aug_exp1_2_0.228576.hdf5\n",
      "Epoch 3/200\n",
      "8112/8112 [==============================] - 273s 34ms/step - loss: 0.1281 - accuracy: 0.9951 - sens: 0.9697 - dice_coef_loss: 0.1281 - val_loss: 0.1096 - val_accuracy: 0.9941 - val_sens: 0.9639 - val_dice_coef_loss: 0.1097\n",
      "\n",
      "Epoch 00003: val_dice_coef_loss improved from 0.21007 to 0.10970, saving model to ./4_result/exp1/snapshot/AP/ap_aug_exp1_3_0.128080.hdf5\n",
      "Epoch 4/200\n",
      "8112/8112 [==============================] - 270s 33ms/step - loss: 0.0802 - accuracy: 0.9961 - sens: 0.9732 - dice_coef_loss: 0.0802 - val_loss: 0.1431 - val_accuracy: 0.9864 - val_sens: 0.8417 - val_dice_coef_loss: 0.1434\n",
      "\n",
      "Epoch 00004: val_dice_coef_loss did not improve from 0.10970\n",
      "Epoch 5/200\n",
      "8112/8112 [==============================] - 269s 33ms/step - loss: 0.0568 - accuracy: 0.9964 - sens: 0.9751 - dice_coef_loss: 0.0568 - val_loss: 0.0673 - val_accuracy: 0.9940 - val_sens: 0.9531 - val_dice_coef_loss: 0.0674\n",
      "\n",
      "Epoch 00005: val_dice_coef_loss improved from 0.10970 to 0.06740, saving model to ./4_result/exp1/snapshot/AP/ap_aug_exp1_5_0.056806.hdf5\n",
      "Epoch 6/200\n",
      "8112/8112 [==============================] - 270s 33ms/step - loss: 0.0415 - accuracy: 0.9970 - sens: 0.9788 - dice_coef_loss: 0.0415 - val_loss: 0.0602 - val_accuracy: 0.9936 - val_sens: 0.9699 - val_dice_coef_loss: 0.0603\n",
      "\n",
      "Epoch 00006: val_dice_coef_loss improved from 0.06740 to 0.06034, saving model to ./4_result/exp1/snapshot/AP/ap_aug_exp1_6_0.041477.hdf5\n",
      "Epoch 7/200\n",
      "8112/8112 [==============================] - 272s 34ms/step - loss: 0.0327 - accuracy: 0.9973 - sens: 0.9804 - dice_coef_loss: 0.0327 - val_loss: 0.0605 - val_accuracy: 0.9933 - val_sens: 0.9264 - val_dice_coef_loss: 0.0608\n",
      "\n",
      "Epoch 00007: val_dice_coef_loss did not improve from 0.06034\n",
      "Epoch 8/200\n",
      "8112/8112 [==============================] - 272s 34ms/step - loss: 0.0290 - accuracy: 0.9972 - sens: 0.9800 - dice_coef_loss: 0.0290 - val_loss: 0.0343 - val_accuracy: 0.9963 - val_sens: 0.9707 - val_dice_coef_loss: 0.0344\n",
      "\n",
      "Epoch 00008: val_dice_coef_loss improved from 0.06034 to 0.03443, saving model to ./4_result/exp1/snapshot/AP/ap_aug_exp1_8_0.028961.hdf5\n",
      "Epoch 9/200\n",
      "8112/8112 [==============================] - 273s 34ms/step - loss: 0.0249 - accuracy: 0.9974 - sens: 0.9818 - dice_coef_loss: 0.0249 - val_loss: 0.0679 - val_accuracy: 0.9905 - val_sens: 0.9784 - val_dice_coef_loss: 0.0681\n",
      "\n",
      "Epoch 00009: val_dice_coef_loss did not improve from 0.03443\n",
      "Epoch 10/200\n",
      "8112/8112 [==============================] - 274s 34ms/step - loss: 0.0216 - accuracy: 0.9976 - sens: 0.9830 - dice_coef_loss: 0.0216 - val_loss: 0.0335 - val_accuracy: 0.9958 - val_sens: 0.9671 - val_dice_coef_loss: 0.0336\n",
      "\n",
      "Epoch 00010: val_dice_coef_loss improved from 0.03443 to 0.03362, saving model to ./4_result/exp1/snapshot/AP/ap_aug_exp1_10_0.021636.hdf5\n",
      "Epoch 11/200\n",
      "8112/8112 [==============================] - 272s 33ms/step - loss: 0.0197 - accuracy: 0.9977 - sens: 0.9836 - dice_coef_loss: 0.0197 - val_loss: 0.0264 - val_accuracy: 0.9967 - val_sens: 0.9694 - val_dice_coef_loss: 0.0265\n",
      "\n",
      "Epoch 00011: val_dice_coef_loss improved from 0.03362 to 0.02647, saving model to ./4_result/exp1/snapshot/AP/ap_aug_exp1_11_0.019715.hdf5\n",
      "Epoch 12/200\n",
      "8112/8112 [==============================] - 270s 33ms/step - loss: 0.0188 - accuracy: 0.9977 - sens: 0.9836 - dice_coef_loss: 0.0188 - val_loss: 0.0528 - val_accuracy: 0.9930 - val_sens: 0.9182 - val_dice_coef_loss: 0.0530\n",
      "\n",
      "Epoch 00012: val_dice_coef_loss did not improve from 0.02647\n",
      "Epoch 13/200\n",
      "8112/8112 [==============================] - 270s 33ms/step - loss: 0.0181 - accuracy: 0.9977 - sens: 0.9838 - dice_coef_loss: 0.0181 - val_loss: 0.0227 - val_accuracy: 0.9970 - val_sens: 0.9780 - val_dice_coef_loss: 0.0229\n",
      "\n",
      "Epoch 00013: val_dice_coef_loss improved from 0.02647 to 0.02288, saving model to ./4_result/exp1/snapshot/AP/ap_aug_exp1_13_0.018149.hdf5\n",
      "Epoch 14/200\n",
      "8112/8112 [==============================] - 271s 33ms/step - loss: 0.0163 - accuracy: 0.9979 - sens: 0.9854 - dice_coef_loss: 0.0163 - val_loss: 0.0249 - val_accuracy: 0.9967 - val_sens: 0.9770 - val_dice_coef_loss: 0.0250\n",
      "\n",
      "Epoch 00014: val_dice_coef_loss did not improve from 0.02288\n",
      "Epoch 15/200\n",
      "8112/8112 [==============================] - 271s 33ms/step - loss: 0.0172 - accuracy: 0.9977 - sens: 0.9841 - dice_coef_loss: 0.0172 - val_loss: 0.0313 - val_accuracy: 0.9959 - val_sens: 0.9584 - val_dice_coef_loss: 0.0314\n",
      "\n",
      "Epoch 00015: val_dice_coef_loss did not improve from 0.02288\n",
      "Epoch 16/200\n",
      "8112/8112 [==============================] - 271s 33ms/step - loss: 0.0160 - accuracy: 0.9978 - sens: 0.9851 - dice_coef_loss: 0.0160 - val_loss: 0.0242 - val_accuracy: 0.9967 - val_sens: 0.9681 - val_dice_coef_loss: 0.0242\n",
      "\n",
      "Epoch 00016: val_dice_coef_loss did not improve from 0.02288\n",
      "Epoch 17/200\n",
      "8112/8112 [==============================] - 271s 33ms/step - loss: 0.0158 - accuracy: 0.9979 - sens: 0.9852 - dice_coef_loss: 0.0158 - val_loss: 0.0351 - val_accuracy: 0.9950 - val_sens: 0.9740 - val_dice_coef_loss: 0.0353\n",
      "\n",
      "Epoch 00017: val_dice_coef_loss did not improve from 0.02288\n",
      "Epoch 18/200\n",
      "8112/8112 [==============================] - 266s 33ms/step - loss: 0.0158 - accuracy: 0.9978 - sens: 0.9848 - dice_coef_loss: 0.0158 - val_loss: 0.0203 - val_accuracy: 0.9972 - val_sens: 0.9773 - val_dice_coef_loss: 0.0204\n",
      "\n",
      "Epoch 00018: val_dice_coef_loss improved from 0.02288 to 0.02037, saving model to ./4_result/exp1/snapshot/AP/ap_aug_exp1_18_0.015782.hdf5\n",
      "Epoch 19/200\n",
      "8112/8112 [==============================] - 267s 33ms/step - loss: 0.0134 - accuracy: 0.9982 - sens: 0.9872 - dice_coef_loss: 0.0134 - val_loss: 0.0209 - val_accuracy: 0.9971 - val_sens: 0.9765 - val_dice_coef_loss: 0.0210\n",
      "\n",
      "Epoch 00019: val_dice_coef_loss did not improve from 0.02037\n",
      "Epoch 20/200\n",
      "8112/8112 [==============================] - 267s 33ms/step - loss: 0.0140 - accuracy: 0.9981 - sens: 0.9867 - dice_coef_loss: 0.0140 - val_loss: 0.0246 - val_accuracy: 0.9966 - val_sens: 0.9666 - val_dice_coef_loss: 0.0247\n",
      "\n",
      "Epoch 00020: val_dice_coef_loss did not improve from 0.02037\n",
      "Epoch 21/200\n",
      "8112/8112 [==============================] - 265s 33ms/step - loss: 0.0131 - accuracy: 0.9982 - sens: 0.9874 - dice_coef_loss: 0.0131 - val_loss: 0.0196 - val_accuracy: 0.9973 - val_sens: 0.9771 - val_dice_coef_loss: 0.0197\n",
      "\n",
      "Epoch 00021: val_dice_coef_loss improved from 0.02037 to 0.01973, saving model to ./4_result/exp1/snapshot/AP/ap_aug_exp1_21_0.013138.hdf5\n",
      "Epoch 22/200\n",
      "8112/8112 [==============================] - 267s 33ms/step - loss: 0.0133 - accuracy: 0.9981 - sens: 0.9872 - dice_coef_loss: 0.0133 - val_loss: 0.0208 - val_accuracy: 0.9971 - val_sens: 0.9829 - val_dice_coef_loss: 0.0209\n",
      "\n",
      "Epoch 00022: val_dice_coef_loss did not improve from 0.01973\n",
      "Epoch 23/200\n",
      "8112/8112 [==============================] - 268s 33ms/step - loss: 0.0147 - accuracy: 0.9979 - sens: 0.9856 - dice_coef_loss: 0.0147 - val_loss: 0.0209 - val_accuracy: 0.9971 - val_sens: 0.9743 - val_dice_coef_loss: 0.0210\n",
      "\n",
      "Epoch 00023: val_dice_coef_loss did not improve from 0.01973\n",
      "Epoch 24/200\n",
      "8112/8112 [==============================] - 267s 33ms/step - loss: 0.0139 - accuracy: 0.9981 - sens: 0.9866 - dice_coef_loss: 0.0139 - val_loss: 0.0202 - val_accuracy: 0.9972 - val_sens: 0.9784 - val_dice_coef_loss: 0.0203\n",
      "\n",
      "Epoch 00024: val_dice_coef_loss did not improve from 0.01973\n",
      "Epoch 25/200\n",
      "8112/8112 [==============================] - 265s 33ms/step - loss: 0.0127 - accuracy: 0.9982 - sens: 0.9879 - dice_coef_loss: 0.0127 - val_loss: 0.0185 - val_accuracy: 0.9974 - val_sens: 0.9802 - val_dice_coef_loss: 0.0186\n",
      "\n",
      "Epoch 00025: val_dice_coef_loss improved from 0.01973 to 0.01856, saving model to ./4_result/exp1/snapshot/AP/ap_aug_exp1_25_0.012698.hdf5\n",
      "Epoch 26/200\n",
      "8112/8112 [==============================] - 266s 33ms/step - loss: 0.0125 - accuracy: 0.9982 - sens: 0.9879 - dice_coef_loss: 0.0125 - val_loss: 0.0249 - val_accuracy: 0.9965 - val_sens: 0.9691 - val_dice_coef_loss: 0.0250\n",
      "\n",
      "Epoch 00026: val_dice_coef_loss did not improve from 0.01856\n",
      "Epoch 27/200\n",
      "8112/8112 [==============================] - 265s 33ms/step - loss: 0.0127 - accuracy: 0.9982 - sens: 0.9877 - dice_coef_loss: 0.0127 - val_loss: 0.0412 - val_accuracy: 0.9945 - val_sens: 0.9358 - val_dice_coef_loss: 0.0417\n",
      "\n",
      "Epoch 00027: val_dice_coef_loss did not improve from 0.01856\n",
      "Epoch 28/200\n",
      "8112/8112 [==============================] - 265s 33ms/step - loss: 0.0127 - accuracy: 0.9982 - sens: 0.9878 - dice_coef_loss: 0.0127 - val_loss: 0.0243 - val_accuracy: 0.9966 - val_sens: 0.9778 - val_dice_coef_loss: 0.0244\n",
      "\n",
      "Epoch 00028: val_dice_coef_loss did not improve from 0.01856\n",
      "Epoch 29/200\n",
      "8112/8112 [==============================] - 268s 33ms/step - loss: 0.0125 - accuracy: 0.9982 - sens: 0.9879 - dice_coef_loss: 0.0125 - val_loss: 0.0191 - val_accuracy: 0.9973 - val_sens: 0.9790 - val_dice_coef_loss: 0.0191\n",
      "\n",
      "Epoch 00029: val_dice_coef_loss did not improve from 0.01856\n",
      "Epoch 30/200\n",
      "8112/8112 [==============================] - 265s 33ms/step - loss: 0.0119 - accuracy: 0.9983 - sens: 0.9885 - dice_coef_loss: 0.0119 - val_loss: 0.0177 - val_accuracy: 0.9975 - val_sens: 0.9810 - val_dice_coef_loss: 0.0178\n",
      "\n",
      "Epoch 00030: val_dice_coef_loss improved from 0.01856 to 0.01780, saving model to ./4_result/exp1/snapshot/AP/ap_aug_exp1_30_0.011899.hdf5\n",
      "Epoch 31/200\n",
      "8112/8112 [==============================] - 266s 33ms/step - loss: 0.0112 - accuracy: 0.9984 - sens: 0.9892 - dice_coef_loss: 0.0112 - val_loss: 0.0188 - val_accuracy: 0.9974 - val_sens: 0.9821 - val_dice_coef_loss: 0.0189\n",
      "\n",
      "Epoch 00031: val_dice_coef_loss did not improve from 0.01780\n",
      "Epoch 32/200\n",
      "8112/8112 [==============================] - 268s 33ms/step - loss: 0.0110 - accuracy: 0.9984 - sens: 0.9894 - dice_coef_loss: 0.0110 - val_loss: 0.0191 - val_accuracy: 0.9973 - val_sens: 0.9802 - val_dice_coef_loss: 0.0191\n",
      "\n",
      "Epoch 00032: val_dice_coef_loss did not improve from 0.01780\n",
      "Epoch 33/200\n",
      "8112/8112 [==============================] - 266s 33ms/step - loss: 0.0137 - accuracy: 0.9981 - sens: 0.9867 - dice_coef_loss: 0.0137 - val_loss: 0.0300 - val_accuracy: 0.9959 - val_sens: 0.9567 - val_dice_coef_loss: 0.0303\n",
      "\n",
      "Epoch 00033: val_dice_coef_loss did not improve from 0.01780\n",
      "Epoch 34/200\n",
      "8112/8112 [==============================] - 266s 33ms/step - loss: 0.0120 - accuracy: 0.9983 - sens: 0.9883 - dice_coef_loss: 0.0120 - val_loss: 0.0405 - val_accuracy: 0.9940 - val_sens: 0.9824 - val_dice_coef_loss: 0.0407\n",
      "\n",
      "Epoch 00034: val_dice_coef_loss did not improve from 0.01780\n",
      "Epoch 35/200\n",
      "8112/8112 [==============================] - 267s 33ms/step - loss: 0.0111 - accuracy: 0.9984 - sens: 0.9894 - dice_coef_loss: 0.0111 - val_loss: 0.0176 - val_accuracy: 0.9975 - val_sens: 0.9797 - val_dice_coef_loss: 0.0177\n",
      "\n",
      "Epoch 00035: val_dice_coef_loss improved from 0.01780 to 0.01771, saving model to ./4_result/exp1/snapshot/AP/ap_aug_exp1_35_0.011095.hdf5\n",
      "Epoch 36/200\n",
      "8112/8112 [==============================] - 265s 33ms/step - loss: 0.0107 - accuracy: 0.9985 - sens: 0.9897 - dice_coef_loss: 0.0107 - val_loss: 0.0185 - val_accuracy: 0.9974 - val_sens: 0.9804 - val_dice_coef_loss: 0.0186\n",
      "\n",
      "Epoch 00036: val_dice_coef_loss did not improve from 0.01771\n",
      "Epoch 37/200\n",
      "8112/8112 [==============================] - 266s 33ms/step - loss: 0.0105 - accuracy: 0.9985 - sens: 0.9900 - dice_coef_loss: 0.0105 - val_loss: 0.0180 - val_accuracy: 0.9975 - val_sens: 0.9800 - val_dice_coef_loss: 0.0180\n",
      "\n",
      "Epoch 00037: val_dice_coef_loss did not improve from 0.01771\n",
      "Epoch 38/200\n",
      "8112/8112 [==============================] - 266s 33ms/step - loss: 0.0117 - accuracy: 0.9983 - sens: 0.9886 - dice_coef_loss: 0.0117 - val_loss: 0.1584 - val_accuracy: 0.9805 - val_sens: 0.7672 - val_dice_coef_loss: 0.1586\n",
      "\n",
      "Epoch 00038: val_dice_coef_loss did not improve from 0.01771\n",
      "Epoch 39/200\n",
      "8112/8112 [==============================] - 266s 33ms/step - loss: 0.0134 - accuracy: 0.9981 - sens: 0.9870 - dice_coef_loss: 0.0134 - val_loss: 0.0216 - val_accuracy: 0.9969 - val_sens: 0.9802 - val_dice_coef_loss: 0.0218\n",
      "\n",
      "Epoch 00039: val_dice_coef_loss did not improve from 0.01771\n",
      "Epoch 40/200\n",
      "8112/8112 [==============================] - 267s 33ms/step - loss: 0.0109 - accuracy: 0.9985 - sens: 0.9894 - dice_coef_loss: 0.0109 - val_loss: 0.0205 - val_accuracy: 0.9971 - val_sens: 0.9738 - val_dice_coef_loss: 0.0206\n",
      "\n",
      "Epoch 00040: val_dice_coef_loss did not improve from 0.01771\n",
      "Epoch 41/200\n",
      "8112/8112 [==============================] - 267s 33ms/step - loss: 0.0118 - accuracy: 0.9983 - sens: 0.9884 - dice_coef_loss: 0.0118 - val_loss: 0.0192 - val_accuracy: 0.9973 - val_sens: 0.9781 - val_dice_coef_loss: 0.0193\n",
      "\n",
      "Epoch 00041: val_dice_coef_loss did not improve from 0.01771\n",
      "Epoch 42/200\n",
      "8112/8112 [==============================] - 267s 33ms/step - loss: 0.0104 - accuracy: 0.9985 - sens: 0.9900 - dice_coef_loss: 0.0104 - val_loss: 0.0184 - val_accuracy: 0.9974 - val_sens: 0.9784 - val_dice_coef_loss: 0.0184\n",
      "\n",
      "Epoch 00042: val_dice_coef_loss did not improve from 0.01771\n",
      "Epoch 43/200\n",
      "8112/8112 [==============================] - 266s 33ms/step - loss: 0.0100 - accuracy: 0.9986 - sens: 0.9904 - dice_coef_loss: 0.0100 - val_loss: 0.0177 - val_accuracy: 0.9975 - val_sens: 0.9812 - val_dice_coef_loss: 0.0177\n",
      "\n",
      "Epoch 00043: val_dice_coef_loss did not improve from 0.01771\n",
      "Epoch 44/200\n",
      "8112/8112 [==============================] - 267s 33ms/step - loss: 0.0099 - accuracy: 0.9986 - sens: 0.9905 - dice_coef_loss: 0.0099 - val_loss: 0.0174 - val_accuracy: 0.9976 - val_sens: 0.9798 - val_dice_coef_loss: 0.0175\n",
      "\n",
      "Epoch 00044: val_dice_coef_loss improved from 0.01771 to 0.01752, saving model to ./4_result/exp1/snapshot/AP/ap_aug_exp1_44_0.009884.hdf5\n",
      "Epoch 45/200\n",
      "8112/8112 [==============================] - 267s 33ms/step - loss: 0.0128 - accuracy: 0.9982 - sens: 0.9876 - dice_coef_loss: 0.0128 - val_loss: 0.0190 - val_accuracy: 0.9973 - val_sens: 0.9771 - val_dice_coef_loss: 0.0191\n",
      "\n",
      "Epoch 00045: val_dice_coef_loss did not improve from 0.01752\n",
      "Epoch 46/200\n",
      "8112/8112 [==============================] - 265s 33ms/step - loss: 0.0103 - accuracy: 0.9985 - sens: 0.9901 - dice_coef_loss: 0.0103 - val_loss: 0.0177 - val_accuracy: 0.9975 - val_sens: 0.9793 - val_dice_coef_loss: 0.0178\n",
      "\n",
      "Epoch 00046: val_dice_coef_loss did not improve from 0.01752\n",
      "Epoch 47/200\n",
      "8112/8112 [==============================] - 266s 33ms/step - loss: 0.0098 - accuracy: 0.9986 - sens: 0.9906 - dice_coef_loss: 0.0098 - val_loss: 0.0176 - val_accuracy: 0.9975 - val_sens: 0.9795 - val_dice_coef_loss: 0.0177\n",
      "\n",
      "Epoch 00047: val_dice_coef_loss did not improve from 0.01752\n",
      "Epoch 48/200\n",
      "8112/8112 [==============================] - 264s 33ms/step - loss: 0.0106 - accuracy: 0.9985 - sens: 0.9898 - dice_coef_loss: 0.0106 - val_loss: 0.0390 - val_accuracy: 0.9944 - val_sens: 0.9732 - val_dice_coef_loss: 0.0391\n",
      "\n",
      "Epoch 00048: val_dice_coef_loss did not improve from 0.01752\n",
      "Epoch 49/200\n",
      "8112/8112 [==============================] - 264s 33ms/step - loss: 0.0108 - accuracy: 0.9985 - sens: 0.9897 - dice_coef_loss: 0.0108 - val_loss: 0.0182 - val_accuracy: 0.9975 - val_sens: 0.9801 - val_dice_coef_loss: 0.0183\n",
      "\n",
      "Epoch 00049: val_dice_coef_loss did not improve from 0.01752\n",
      "Epoch 50/200\n",
      "8112/8112 [==============================] - 265s 33ms/step - loss: 0.0096 - accuracy: 0.9987 - sens: 0.9908 - dice_coef_loss: 0.0096 - val_loss: 0.0176 - val_accuracy: 0.9975 - val_sens: 0.9817 - val_dice_coef_loss: 0.0177\n",
      "\n",
      "Epoch 00050: val_dice_coef_loss did not improve from 0.01752\n",
      "Epoch 51/200\n",
      "8112/8112 [==============================] - 266s 33ms/step - loss: 0.0095 - accuracy: 0.9987 - sens: 0.9909 - dice_coef_loss: 0.0095 - val_loss: 0.0180 - val_accuracy: 0.9975 - val_sens: 0.9796 - val_dice_coef_loss: 0.0181\n",
      "\n",
      "Epoch 00051: val_dice_coef_loss did not improve from 0.01752\n",
      "Epoch 52/200\n",
      "8112/8112 [==============================] - 266s 33ms/step - loss: 0.0093 - accuracy: 0.9987 - sens: 0.9910 - dice_coef_loss: 0.0093 - val_loss: 0.0181 - val_accuracy: 0.9975 - val_sens: 0.9791 - val_dice_coef_loss: 0.0181\n",
      "\n",
      "Epoch 00052: val_dice_coef_loss did not improve from 0.01752\n",
      "Epoch 53/200\n",
      "8112/8112 [==============================] - 265s 33ms/step - loss: 0.0092 - accuracy: 0.9987 - sens: 0.9912 - dice_coef_loss: 0.0092 - val_loss: 0.0174 - val_accuracy: 0.9976 - val_sens: 0.9803 - val_dice_coef_loss: 0.0175\n",
      "\n",
      "Epoch 00053: val_dice_coef_loss improved from 0.01752 to 0.01750, saving model to ./4_result/exp1/snapshot/AP/ap_aug_exp1_53_0.009178.hdf5\n",
      "Epoch 54/200\n",
      "8112/8112 [==============================] - 265s 33ms/step - loss: 0.0091 - accuracy: 0.9987 - sens: 0.9912 - dice_coef_loss: 0.0091 - val_loss: 0.0177 - val_accuracy: 0.9975 - val_sens: 0.9807 - val_dice_coef_loss: 0.0178\n",
      "\n",
      "Epoch 00054: val_dice_coef_loss did not improve from 0.01750\n",
      "Epoch 55/200\n",
      "8112/8112 [==============================] - 266s 33ms/step - loss: 0.0108 - accuracy: 0.9985 - sens: 0.9896 - dice_coef_loss: 0.0108 - val_loss: 0.0234 - val_accuracy: 0.9967 - val_sens: 0.9780 - val_dice_coef_loss: 0.0234\n",
      "\n",
      "Epoch 00055: val_dice_coef_loss did not improve from 0.01750\n",
      "Epoch 56/200\n",
      "8112/8112 [==============================] - 265s 33ms/step - loss: 0.0099 - accuracy: 0.9986 - sens: 0.9904 - dice_coef_loss: 0.0099 - val_loss: 0.0276 - val_accuracy: 0.9961 - val_sens: 0.9660 - val_dice_coef_loss: 0.0277\n",
      "\n",
      "Epoch 00056: val_dice_coef_loss did not improve from 0.01750\n",
      "Epoch 57/200\n",
      "8112/8112 [==============================] - 267s 33ms/step - loss: 0.0100 - accuracy: 0.9986 - sens: 0.9904 - dice_coef_loss: 0.0100 - val_loss: 0.0181 - val_accuracy: 0.9975 - val_sens: 0.9787 - val_dice_coef_loss: 0.0182\n",
      "\n",
      "Epoch 00057: val_dice_coef_loss did not improve from 0.01750\n",
      "Epoch 58/200\n",
      "8112/8112 [==============================] - 266s 33ms/step - loss: 0.0091 - accuracy: 0.9987 - sens: 0.9913 - dice_coef_loss: 0.0091 - val_loss: 0.0182 - val_accuracy: 0.9975 - val_sens: 0.9801 - val_dice_coef_loss: 0.0183\n",
      "\n",
      "Epoch 00058: val_dice_coef_loss did not improve from 0.01750\n",
      "Epoch 59/200\n",
      "8112/8112 [==============================] - 265s 33ms/step - loss: 0.0091 - accuracy: 0.9987 - sens: 0.9912 - dice_coef_loss: 0.0091 - val_loss: 0.0184 - val_accuracy: 0.9974 - val_sens: 0.9802 - val_dice_coef_loss: 0.0185\n",
      "\n",
      "Epoch 00059: val_dice_coef_loss did not improve from 0.01750\n",
      "Epoch 60/200\n",
      "8112/8112 [==============================] - 265s 33ms/step - loss: 0.0086 - accuracy: 0.9988 - sens: 0.9918 - dice_coef_loss: 0.0086 - val_loss: 0.0176 - val_accuracy: 0.9975 - val_sens: 0.9802 - val_dice_coef_loss: 0.0176\n",
      "\n",
      "Epoch 00060: val_dice_coef_loss did not improve from 0.01750\n",
      "Epoch 61/200\n",
      "8112/8112 [==============================] - 267s 33ms/step - loss: 0.0102 - accuracy: 0.9986 - sens: 0.9902 - dice_coef_loss: 0.0102 - val_loss: 0.0248 - val_accuracy: 0.9965 - val_sens: 0.9702 - val_dice_coef_loss: 0.0249\n",
      "\n",
      "Epoch 00061: val_dice_coef_loss did not improve from 0.01750\n",
      "Epoch 62/200\n",
      "8112/8112 [==============================] - 266s 33ms/step - loss: 0.0090 - accuracy: 0.9987 - sens: 0.9914 - dice_coef_loss: 0.0090 - val_loss: 0.0175 - val_accuracy: 0.9976 - val_sens: 0.9801 - val_dice_coef_loss: 0.0175\n",
      "\n",
      "Epoch 00062: val_dice_coef_loss did not improve from 0.01750\n",
      "Epoch 63/200\n",
      "8112/8112 [==============================] - 265s 33ms/step - loss: 0.0083 - accuracy: 0.9988 - sens: 0.9920 - dice_coef_loss: 0.0083 - val_loss: 0.0178 - val_accuracy: 0.9975 - val_sens: 0.9789 - val_dice_coef_loss: 0.0179\n",
      "\n",
      "Epoch 00063: val_dice_coef_loss did not improve from 0.01750\n",
      "save model\n",
      "predict test data\n",
      "254/254 [==============================] - 12s 48ms/step\n"
     ]
    }
   ],
   "source": [
    "print('Fitting model...')\n",
    "model.fit(imgs_train, imgs_mask_train, batch_size=16, epochs=200, verbose=1, validation_split=0.2, shuffle=True, callbacks=[model_checkpoint, earlystopping])\n",
    "\n",
    "print('save model')\n",
    "model.save(predict_path+'ap_aug_exp1.h5')\n",
    "\n",
    "print('predict test data')\n",
    "imgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n",
    "np.save(predict_path+'prediction_ap_aug_exp1.npy', imgs_mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254, 512, 512, 1)\n",
      "complete\n",
      "acc avg : 0.9988\n",
      "sensitivity avg : 0.9791\n",
      "specificity avg : 0.9995\n",
      "dsc avg : 0.9807\n",
      "save file\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import r2_score\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "\n",
    "name_list=np.load('./3_deepdata/1_exp1/npy/AP/test_name.npy')\n",
    "df = pd.DataFrame(columns=['name', 'acc', 'sen', 'spe', 'dsc'])\n",
    "\n",
    "true_list=np.load('./3_deepdata/1_exp1/npy/AP/test_label.npy')\n",
    "true_list=true_list.astype('float32')\n",
    "true_list = true_list/255.0\n",
    "true_list[true_list > 0.5] = 1\n",
    "true_list[true_list <= 0.5] = 0\n",
    "print(true_list.shape)\n",
    "\n",
    "pred_list=np.load('./4_result/exp1/result/AP/prediction_ap_aug_exp1.npy')\n",
    "pred_list[pred_list > 0.5] = 1\n",
    "pred_list[pred_list <= 0.5] = 0\n",
    "# pred_list[pred_list > 127] = 1\n",
    "# pred_list[pred_list <= 127] = 0\n",
    "\n",
    "sensitivity=[]\n",
    "specificity=[]\n",
    "acc=[]\n",
    "dsc=[]\n",
    "\n",
    "for i in range(len(true_list)):\n",
    "    yt=true_list[i].flatten()\n",
    "    yp=pred_list[i].flatten()\n",
    "    mat=confusion_matrix(yt,yp)\n",
    "    if len(mat) == 2:\n",
    "        ac=(mat[1,1]+mat[0,0])/(mat[1,0]+mat[1,1]+mat[0,1]+mat[0,0])\n",
    "        st=mat[1,1]/(mat[1,0]+mat[1,1])\n",
    "        sp=mat[0,0]/(mat[0,1]+mat[0,0])\n",
    "        if mat[1,0]+mat[1,1] == 0:\n",
    "            specificity.append(sp)\n",
    "            acc.append(ac)\n",
    "        else:\n",
    "            sensitivity.append(st)  \n",
    "            specificity.append(sp)\n",
    "            acc.append(ac)\n",
    "    else:\n",
    "        specificity.append(1)\n",
    "        acc.append(1)\n",
    "\n",
    "# for i in range(len(true_list)):\n",
    "    yt=true_list[i]\n",
    "    yp=pred_list[i]\n",
    "    if np.sum(yt) != 0 and np.sum(yp) != 0:\n",
    "        dice = np.sum(yp[yt==1])*2.0 / (np.sum(yt) + np.sum(yp))\n",
    "        dsc.append(dice)\n",
    "    df=  df.append({'name':name_list[i], 'acc':ac, 'sen':st, 'spe':sp, 'dsc':dice}, ignore_index=True)\n",
    "\n",
    "print(\"complete\")      \n",
    "print(\"acc avg : {0:0.4f}\".format(np.mean(acc)))\n",
    "print(\"sensitivity avg : {0:0.4f}\".format(np.mean(sensitivity)))\n",
    "print(\"specificity avg : {0:0.4f}\".format(np.mean(specificity)))\n",
    "print(\"dsc avg : {0:0.4f}\".format(np.mean(dsc)))\n",
    "\n",
    "# print(\"sensitivity min:\",np.min(sensitivity))\n",
    "# print(\"specificity min:\",np.min(specificity))\n",
    "# print(\"dsc min:\",np.min(dsc))\n",
    "# print(\"acc min:\",np.min(acc))\n",
    "\n",
    "# print(\"sensitivity max:\",np.max(sensitivity))\n",
    "# print(\"specificity max:\",np.max(specificity))\n",
    "# print(\"dsc max:\",np.max(dsc))\n",
    "# print(\"acc max:\",np.max(acc))\n",
    "\n",
    "print('save file')\n",
    "df.to_csv('./4_result/exp1/result/AP/ap_aug_exp1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array to image\n"
     ]
    }
   ],
   "source": [
    "pred_img_path = './4_result/exp1/result/AP/exp1_img/'\n",
    "if not os.path.isdir(pred_img_path):\n",
    "    os.makedirs(pred_img_path)\n",
    "\n",
    "# pred_list=np.load('./4_ap_pre_pred/ap_pre_exp2.npy')\n",
    "# pred_list[pred_list > 0.5] = 1\n",
    "# pred_list[pred_list <= 0.5] = 0\n",
    "\n",
    "# name_list=np.load('./2_AP_pre_npy/test_pre_name.npy')\n",
    "print(\"array to image\")\n",
    "imgs = pred_list\n",
    "for i in range(imgs.shape[0]):\n",
    "    img = imgs[i]\n",
    "    img[img <= 0.5] = 0\n",
    "    img[img > 0.5] = 255\n",
    "    img = array_to_img(img)\n",
    "    img.save(pred_img_path+\"%s_pred.png\" %(name_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array to overlay image\n"
     ]
    }
   ],
   "source": [
    "pred_overlay_path = './4_result/exp1/result/AP/exp1_overlay/'\n",
    "if not os.path.isdir(pred_overlay_path):\n",
    "    os.makedirs(pred_overlay_path)\n",
    "    \n",
    "print(\"array to overlay image\")\n",
    "imgs = pred_list\n",
    "gts = true_list\n",
    "ori_path = glob.glob('./3_deepdata/1_exp1/test/AP_pre_img/' + '*.png')\n",
    "\n",
    "for i in range(imgs.shape[0]):\n",
    "    img = imgs[i]\n",
    "    ori_imgs = load_img(ori_path[i])\n",
    "    ori_imgs = ori_imgs.resize((512,512))\n",
    "    ori_img = img_to_array(ori_imgs)\n",
    "    img_name = ori_path[i][ori_path[i].rindex('/')+1:ori_path[i].rindex('.')]\n",
    "#     print(img_name)\n",
    "    img[img <= 0.5] = 0\n",
    "    img[img > 0.5] = 255\n",
    "    img = img_to_array(img)\n",
    "    \n",
    "    ori_img[:,:,0] = img[:,:,0]+ori_img[:,:,0]\n",
    "    ori_img[:,:,0][ori_img[:,:,0]>255]=255\n",
    "    ori_img = array_to_img(ori_img)\n",
    "    ori_img.save(pred_overlay_path+\"{}_pred.png\".format(img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array to overlay image\n"
     ]
    }
   ],
   "source": [
    "pred_overlay_path = './4_result/exp1/result/AP/exp1_overlay_tpfnfp/'\n",
    "if not os.path.isdir(pred_overlay_path):\n",
    "    os.makedirs(pred_overlay_path)\n",
    "    \n",
    "print(\"array to overlay image\")\n",
    "imgs = pred_list\n",
    "gts = true_list\n",
    "ori_path = glob.glob('./3_deepdata/1_exp1/test/AP_pre_img/' + '*.png')\n",
    "\n",
    "for i in range(imgs.shape[0]):\n",
    "    img = imgs[i]\n",
    "    gt = gts[i]\n",
    "    ori_imgs = load_img(ori_path[i])\n",
    "    ori_imgs = ori_imgs.resize((512,512))\n",
    "    ori_img = img_to_array(ori_imgs)\n",
    "    img_name = ori_path[i][ori_path[i].rindex('/')+1:ori_path[i].rindex('.')]\n",
    "#     print(img_name)\n",
    "    img[img <= 0.5] = 0\n",
    "    img[img > 0.5] = 255\n",
    "    img = img_to_array(img)\n",
    "    gt[gt <= 0.5] = 0\n",
    "    gt[gt > 0.5] = 255\n",
    "    gt = img_to_array(gt)\n",
    "    \n",
    "    ori_img[:,:,0] = img[:,:,0]+ori_img[:,:,0]\n",
    "    ori_img[:,:,0][ori_img[:,:,0]>255]=255\n",
    "    \n",
    "    ori_img[:,:,1] = gt[:,:,0]+ori_img[:,:,1]\n",
    "    ori_img[:,:,1][ori_img[:,:,1]>255]=255\n",
    "#     print(np.unique(ori_img[:,:,2]))\n",
    "    pred_img = array_to_img(ori_img)\n",
    "    pred_img.save(pred_overlay_path+\"{}_pred.png\".format(img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "\n",
    "def max_contour(img):\n",
    "    contours, _ = cv2.findContours(img, cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "    tmp =[]\n",
    "#     print(len(contours))\n",
    "    for k in range(len(contours)):\n",
    "        cnt = contours[k]\n",
    "        mmt = cv2.moments(cnt) \n",
    "        tmp.append(float(mmt['m00']))\n",
    "\n",
    "    max_num = max(tmp)\n",
    "    index = tmp.index(max_num)\n",
    "#     contour = contours[index]\n",
    "    return contours, index\n",
    "    \n",
    "def postprocessing(img):\n",
    "    img = img.astype('uint8')\n",
    "#     print(img.dtype)\n",
    "    ret, thresh = cv2.threshold(img,127,255,0)\n",
    "    img = ndimage.binary_fill_holes(thresh).astype('uint8')\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "#     print(img.shape)\n",
    "    \n",
    "    contours, max_cnt_index = max_contour(img)\n",
    "    \n",
    "    for i, contour in enumerate(contours):\n",
    "        if i!=max_cnt_index:\n",
    "            cv2.fillPoly(img, [contour], color=(0,0,0))\n",
    "#         else:\n",
    "#             cv2.fillPoly(img, [contour], color=(255,255,255))\n",
    "    kernel = np.ones((7,7), np.uint8)\n",
    "    morph_cnt = 8\n",
    "#     imshow_plt(img)\n",
    "#     print(img.shape)\n",
    "    img_m = img.copy()\n",
    "    for j in range(morph_cnt):\n",
    "        img_m = cv2.morphologyEx(img_m, cv2.MORPH_DILATE, kernel)\n",
    "#     print(img.shape)\n",
    "#     imshow_plt(img)\n",
    "    for k in range(morph_cnt):\n",
    "        img_m = cv2.morphologyEx(img_m, cv2.MORPH_ERODE, kernel)\n",
    "#     imshow_plt(img)\n",
    "    return img_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path = sorted(glob.glob('./4_result/exp1/result/AP/exp1_img/*.png'))\n",
    "\n",
    "post_img_path = './4_result/exp1/result/AP/exp1_postprocessing/'\n",
    "if not os.path.isdir(post_img_path):\n",
    "    os.makedirs(post_img_path)\n",
    "    \n",
    "for i, img_path in enumerate(imgs_path):\n",
    "    img_name = img_path[img_path.rindex('/')+1:img_path.rindex('_')]\n",
    "#     print(img_name)\n",
    "\n",
    "#     if i==10:\n",
    "#         break\n",
    "    img = cv2.imread(img_path,0)\n",
    "    post_img = postprocessing(img)\n",
    "    post_img = cv2.cvtColor(post_img, cv2.COLOR_GRAY2BGR)\n",
    "#     print(post_img.shape)\n",
    "#     plt.figure(figsize=(15,15))\n",
    "#     plt.imshow(post_img[:,:,0], cmap='gray')\n",
    "#     plt.show()\n",
    "    \n",
    "    post_img = array_to_img(post_img)\n",
    "    post_img.save(post_img_path+\"{}_post.png\".format(img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array to overlay image\n"
     ]
    }
   ],
   "source": [
    "pred_overlay_path = './4_result/exp1/result/AP/exp1_overlay_post/'\n",
    "if not os.path.isdir(pred_overlay_path):\n",
    "    os.makedirs(pred_overlay_path)\n",
    "    \n",
    "print(\"array to overlay image\")\n",
    "imgs = pred_list\n",
    "gts = true_list\n",
    "ori_path = glob.glob('./3_deepdata/1_exp1/test/AP_pre_img/' + '*.png')\n",
    "\n",
    "for i in range(imgs.shape[0]):\n",
    "    img = imgs[i]\n",
    "    ori_imgs = load_img(ori_path[i])\n",
    "    ori_imgs = ori_imgs.resize((512,512))\n",
    "    ori_img = img_to_array(ori_imgs)\n",
    "    img_name = ori_path[i][ori_path[i].rindex('/')+1:ori_path[i].rindex('.')]\n",
    "#     print(img_name)\n",
    "    img[img <= 0.5] = 0\n",
    "    img[img > 0.5] = 255\n",
    "    img = img_to_array(img)\n",
    "    post_img = postprocessing(img)\n",
    "    post_img = cv2.cvtColor(post_img, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    ori_img[:,:,0] = post_img[:,:,0]*255+ori_img[:,:,0]\n",
    "    ori_img[:,:,0][ori_img[:,:,0]>255]=255\n",
    "    ori_img = array_to_img(ori_img)\n",
    "    ori_img.save(pred_overlay_path+\"{}_pred.png\".format(img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array to overlay image\n"
     ]
    }
   ],
   "source": [
    "pred_overlay_path = './4_result/exp1/result/AP/exp1_overlay_post_tpfnfp/'\n",
    "if not os.path.isdir(pred_overlay_path):\n",
    "    os.makedirs(pred_overlay_path)\n",
    "    \n",
    "print(\"array to overlay image\")\n",
    "imgs = pred_list\n",
    "ori_path = glob.glob('./3_deepdata/1_exp1/test/AP_pre_img/' + '*.png')\n",
    "\n",
    "for i in range(imgs.shape[0]):\n",
    "#     if i==1:\n",
    "#         break\n",
    "    img = imgs[i]\n",
    "    ori_imgs = load_img(ori_path[i])\n",
    "    ori_imgs = ori_imgs.resize((512,512))\n",
    "    ori_img = img_to_array(ori_imgs)\n",
    "    img_name = ori_path[i][ori_path[i].rindex('/')+1:ori_path[i].rindex('.')]\n",
    "#     print(img_name)\n",
    "    img[img <= 0.5] = 0\n",
    "    img[img > 0.5] = 255\n",
    "    img = img_to_array(img)\n",
    "    post_img = postprocessing(img)\n",
    "    post_img = cv2.cvtColor(post_img, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    ori_img[:,:,0] = post_img[:,:,0]*255+ori_img[:,:,0]\n",
    "    ori_img[:,:,0][ori_img[:,:,0]>255]=255\n",
    "    \n",
    "#     ori_img[:,:,1] = img[:,:,0]+ori_img[:,:,1]\n",
    "#     ori_img[:,:,1][ori_img[:,:,1]>255]=255\n",
    "    \n",
    "    \n",
    "    ori_img[:,:,1] = img[:,:,0]+ori_img[:,:,1]\n",
    "    ori_img[:,:,1][ori_img[:,:,1]>255]=255\n",
    "    \n",
    "    pred_img = array_to_img(ori_img)\n",
    "    pred_img.save(pred_overlay_path+\"{}_pred.png\".format(img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_plt(img):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    if len(img.shape)==2:\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "    plt.imshow(img[:,:,0], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254, 512, 512, 1)\n",
      "complete\n",
      "acc avg : 0.9982\n",
      "sensitivity avg : 0.9769\n",
      "specificity avg : 0.9989\n",
      "dsc avg : 0.9711\n",
      "save file\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import r2_score\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "\n",
    "name_list=np.load('./3_deepdata/1_exp1/npy/AP/test_name.npy')\n",
    "df = pd.DataFrame(columns=['name', 'acc', 'sen', 'spe', 'dsc'])\n",
    "\n",
    "true_list=np.load('./3_deepdata/1_exp1/npy/AP/test_label.npy')\n",
    "true_list=true_list.astype('float32')\n",
    "true_list = true_list/255.0\n",
    "true_list[true_list > 0.5] = 1\n",
    "true_list[true_list <= 0.5] = 0\n",
    "print(true_list.shape)\n",
    "\n",
    "pred_list=np.array([cv2.imread(path, 0) for path in sorted(glob.glob('./4_result/exp1/result/AP/exp1_postprocessing/*.png'))])\n",
    "pred_list = np.expand_dims(pred_list, axis=-1)\n",
    "pred_list = pred_list/255.0\n",
    "# pred_list[pred_list > 0.5] = 1\n",
    "# pred_list[pred_list <= 0.5] = 0\n",
    "# pred_list[pred_list > 127] = 1\n",
    "# pred_list[pred_list <= 127] = 0\n",
    "\n",
    "sensitivity=[]\n",
    "specificity=[]\n",
    "acc=[]\n",
    "dsc=[]\n",
    "\n",
    "for i in range(len(true_list)):\n",
    "    yt=true_list[i].flatten()\n",
    "    yp=pred_list[i].flatten()\n",
    "    mat=confusion_matrix(yt,yp)\n",
    "    if len(mat) == 2:\n",
    "        ac=(mat[1,1]+mat[0,0])/(mat[1,0]+mat[1,1]+mat[0,1]+mat[0,0])\n",
    "        st=mat[1,1]/(mat[1,0]+mat[1,1])\n",
    "        sp=mat[0,0]/(mat[0,1]+mat[0,0])\n",
    "        if mat[1,0]+mat[1,1] == 0:\n",
    "            specificity.append(sp)\n",
    "            acc.append(ac)\n",
    "        else:\n",
    "            sensitivity.append(st)  \n",
    "            specificity.append(sp)\n",
    "            acc.append(ac)\n",
    "    else:\n",
    "        specificity.append(1)\n",
    "        acc.append(1)\n",
    "\n",
    "# for i in range(len(true_list)):\n",
    "    yt=true_list[i]\n",
    "    yp=pred_list[i]\n",
    "    if np.sum(yt) != 0 and np.sum(yp) != 0:\n",
    "        dice = np.sum(yp[yt==1])*2.0 / (np.sum(yt) + np.sum(yp))\n",
    "        dsc.append(dice)\n",
    "    df=  df.append({'name':name_list[i], 'acc':ac, 'sen':st, 'spe':sp, 'dsc':dice}, ignore_index=True)\n",
    "\n",
    "print(\"complete\")      \n",
    "print(\"acc avg : {0:0.4f}\".format(np.mean(acc)))\n",
    "print(\"sensitivity avg : {0:0.4f}\".format(np.mean(sensitivity)))\n",
    "print(\"specificity avg : {0:0.4f}\".format(np.mean(specificity)))\n",
    "print(\"dsc avg : {0:0.4f}\".format(np.mean(dsc)))\n",
    "\n",
    "# print(\"sensitivity min:\",np.min(sensitivity))\n",
    "# print(\"specificity min:\",np.min(specificity))\n",
    "# print(\"dsc min:\",np.min(dsc))\n",
    "# print(\"acc min:\",np.min(acc))\n",
    "\n",
    "# print(\"sensitivity max:\",np.max(sensitivity))\n",
    "# print(\"specificity max:\",np.max(specificity))\n",
    "# print(\"dsc max:\",np.max(dsc))\n",
    "# print(\"acc max:\",np.max(acc))\n",
    "\n",
    "print('save file')\n",
    "df.to_csv('./4_result/exp1/result/AP/ap_aug_exp1_post.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
